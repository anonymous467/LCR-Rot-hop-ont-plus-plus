# LCR-Rot-hop-ont++
Code for LCR-Rot-hop-ont++.
All software is written in Pyhton 3.7 (https://www.python.org/) and the code uses the TensorFlow framework (https://www.tensorflow.org/).

## Installation Instructions (Windows):
### Dowload required files and add them to data/externalData folder:
1. Download ontology: https://github.com/KSchouten/Heracles/tree/master/src/main/resources/externalData
2. Download SemEval2015 Datasets: http://alt.qcri.org/semeval2015/task12/index.php?id=data-and-tools
3. Download SemEval2016 Dataset: http://alt.qcri.org/semeval2016/task5/index.php?id=data-and-tools 
5. Download Stanford CoreNLP parser: https://nlp.stanford.edu/software/stanford-parser-full-2018-02-27.zip 

### Set-up environment
- Set-up a virtual environment in Anaconda using Python 3.7.
- Open your new environment in the command window.
- Navigate to the file containing all repository code (file_path) by running: cd file_path
- Install the requirements by running the following command: pip install -r requirements.txt
- Install English spacy language pack by running the following command: python -m spacy download en
- You can open and edit the code in any editor, we used the PyCharm IDE: https://www.jetbrains.com/pycharm/

### Choose preferences
1. Choose your own preferences in the config.py file (for example: year, test data, train data, embeddings)
2. Set sofpos and use_vm to True in the createEmbeddings.py file, if you would use the special softpositions and the visible matrix, otherwise choose False
3. Choose in het main.py file which model you would use, and set this boolean to True (We have only used the hierarchical v4 method)

### Run Software
1. Make sure that all the paths in the code are replaced by your own paths
2. Run the generate_data.py file, to obtain the train and test data (already added to programGeneratedData in github)
3. Run the createEmbeddings.py file (in the directory embeddings)
4. Run the main.py file to obtain the accurancy

## Directory explanation:
The following directories are necessary for the virtual environment setup: \__pycache, \Include, \Lib, \Scripts, \tcl, \venv
- data:
    - externalData: Location for the external data that we have used 
    - programGeneratedData: Location for preprocessed data that is generated by the programs
    - temporaryData: Location for temporary data, that is not used for running
- embeddings:
    contains files for creating the embeddings

## Related Work: ##
This code uses ideas and code of the following related papers:
- Liu, W., Zhou, P., Zhao, Z., Wang, Z., Ju, Q., Deng, H., Wang, P.: K-BERT: Enabling language representation with knowledge graph. In: 34th AAAI Conference on Artificial Intelligence (AAAI 2020). vol. 34, pp. 2901–2908. AAAI (2020)
- Trusca, M.M., Wassenberg, D., Frasincar, F., Dekker, R.: A hybrid approach for aspect-based sentiment analysis using deep contextual word embeddings and hierarchical attention. In: 20th International Conference on Web Engineering (ICWE 2020). LNCS, vol. 12128, pp. 365–380. Springer (2020)
- Wallaart, O., Frasincar, F.: A hybrid approach for aspect-based sentiment analysis using a lexicalized domain ontology and attentional neural models. In: 16th Extended Semantic Web Conference (ESWC 2019). LNCS, vol. 11503, pp. 363–378. Springer (2019)
- Yan, X., Jian, F., Sun, B.: SAKG-BERT: Enabling language representation with knowledge graphs for Chinese sentiment analysis. IEEE Access 9, 101695–101701 (2021)
- Zhao, A., Yu, Y.: Knowledge-enabled BERT for aspect-based sentiment analysis. Knowledge-Based Systems 227, 107220 (2021)
- Zheng, S. and Xia, R. (2018). Left-center-right separated neural network for aspect-based sentiment analysis with rotatory attention. arXiv preprint arXiv:1802.00892.


This README.md is based on https://github.com/ofwallaart/HAABSA/blob/master/README.md and https://github.com/stefanvanberkum/CD-ABSC/blob/main/README.md